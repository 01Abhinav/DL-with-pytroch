{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',download = True ,transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/' , train=False , transform = transforms.ToTensor())\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor,label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e435f86f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tensor[0,10:15,12:21] , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds , val_ds = random_split(dataset,[50000,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=128\n",
    "train_loader = DataLoader(train_ds,batch_size,shuffle = True)\n",
    "val_loader = DataLoader(val_ds, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "num_class = 10\n",
    "\n",
    "model = nn.Linear(input_size , num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size,num_class)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        xb=xb.reshape(-1,784)\n",
    "        out=self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self,batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {'val_loss':loss,'val_acc':acc}\n",
    "    \n",
    "    def validation_epoch_end(self,outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()  \n",
    "        batch_accs = torch.Tensor(list([x['val_acc'] for x in outputs]))\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0082, -0.0221,  0.0284,  ..., -0.0203,  0.0283,  0.0315],\n",
       "         [ 0.0048, -0.0165,  0.0041,  ..., -0.0318,  0.0232, -0.0076],\n",
       "         [ 0.0070, -0.0045,  0.0021,  ..., -0.0048, -0.0207,  0.0300],\n",
       "         ...,\n",
       "         [ 0.0342, -0.0050, -0.0042,  ..., -0.0061,  0.0176, -0.0097],\n",
       "         [ 0.0192, -0.0003, -0.0115,  ...,  0.0061,  0.0247,  0.0148],\n",
       "         [ 0.0155,  0.0048,  0.0172,  ...,  0.0237,  0.0299,  0.0332]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0188,  0.0324, -0.0258, -0.0124, -0.0335,  0.0349,  0.0241, -0.0165,\n",
       "          0.0012,  0.0308], requires_grad=True)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) tensor([8, 8, 5, 2, 6, 3, 2, 1, 4, 5, 6, 8, 1, 9, 9, 4, 6, 2, 1, 6, 0, 5, 4, 5,\n",
      "        8, 0, 0, 6, 7, 2, 3, 6, 4, 4, 1, 0, 3, 1, 3, 3, 1, 5, 3, 0, 6, 8, 7, 1,\n",
      "        5, 6, 5, 5, 6, 7, 0, 2, 5, 5, 3, 5, 8, 2, 0, 7, 6, 1, 9, 2, 2, 0, 9, 3,\n",
      "        9, 9, 8, 1, 1, 2, 8, 5, 8, 7, 9, 6, 2, 1, 8, 1, 4, 9, 6, 3, 6, 1, 3, 1,\n",
      "        3, 3, 4, 8, 4, 7, 9, 2, 2, 2, 1, 6, 7, 7, 0, 6, 3, 7, 7, 2, 8, 5, 3, 4,\n",
      "        2, 2, 5, 3, 2, 9, 5, 3])\n",
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "for images , labels in train_loader:\n",
    "    print(images.shape , labels)\n",
    "    output = model(images)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = F.softmax(output, dim=1)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prob,pred = torch.max(prob ,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2462,  0.0846,  0.0964,  ...,  0.0007, -0.2437, -0.0990],\n",
       "        [ 0.2176, -0.0733,  0.0545,  ...,  0.1421, -0.0118,  0.2753],\n",
       "        [ 0.0351, -0.2347, -0.0748,  ...,  0.0340, -0.4901, -0.0184],\n",
       "        ...,\n",
       "        [ 0.2461,  0.2414,  0.0226,  ..., -0.0451, -0.0490, -0.0020],\n",
       "        [ 0.0110,  0.1094, -0.1026,  ...,  0.1137, -0.3813, -0.1205],\n",
       "        [-0.0636,  0.0985,  0.1031,  ..., -0.0669,  0.0018,  0.1758]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output , labels):\n",
    "    _,preds = torch.max(output,dim=1)\n",
    "    return torch.sum(preds == labels).item()/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3218, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_function(output , labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    history = [] # for recording epoch-wise results\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "print(result0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-cea6b237cf8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-7e399a76296e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Validation phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-ea432e9e95fa>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-17245e8fc5df>\u001b[0m in \u001b[0;36mvalidation_epoch_end\u001b[1;34m(self, outputs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mbatch_accs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mepoch_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_accs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "history0 = fit(1, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img,model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb =  model(xb)\n",
    "    _,preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9  predicted: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[7]\n",
    "plt.imshow(img[0],cmap='gray')\n",
    "print('label:',label,' predicted:', predict_image(img,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
